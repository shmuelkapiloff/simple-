/**
 * WEBHOOK RETRY SERVICE - EXPONENTIAL BACKOFF & RESILIENCE
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * PURPOSE & DESIGN PATTERN
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * The Problem:
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Sometimes our webhook handler fails:
 * - Database connection timeout
 * - Redis unavailable (cache write fails)
 * - External email service down
 * - Temporary network issue
 *
 * When webhook handler fails:
 * 1. We throw exception
 * 2. Express error handler catches it
 * 3. Returns 500 error to Stripe
 * 4. Stripe interprets as "delivery failed"
 * 5. Stripe retries webhook with exponential backoff (their side)
 * But what if we still fail after Stripe's retries?
 *
 * Solution: OUR OWN RETRY SERVICE
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 1. When webhook handler fails â†’ Store in FailedWebhookModel
 * 2. Background service checks every 60 seconds
 * 3. Retries failed webhooks with OUR exponential backoff
 * 4. Eventually succeeds when system is healthy
 * 5. Or escalates to manual investigation after max retries
 *
 * WHY EXPONENTIAL BACKOFF?
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Immediate retry: If database is overloaded, immediate retry makes worse
 * Fixed retry (5min): Might wake up too soon before system recovers
 * Exponential backoff: Starts aggressive (1s), gets patient (16+ hours)
 *
 * Backoff Schedule:
 * - Attempt 1: Immediate (webhook handler)
 * - Attempt 2: +1 second (catches transient errors)
 * - Attempt 3: +2 seconds
 * - Attempt 4: +4 seconds
 * - Attempt 5: +8 seconds
 * - Attempt 6: +16 seconds (max for this service)
 * - After max: Alert ops for manual intervention
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * EXECUTION FLOW
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * STARTUP:
 * â”€â”€â”€â”€â”€â”€â”€â”€
 * 1. Server starts (src/server.ts)
 * 2. WebhookRetryService.start() called
 * 3. Sets up interval (default: every 60 seconds)
 * 4. Service runs in background continuously
 *
 * EVERY 60 SECONDS:
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 1. Query: Find all webhooks with status "pending" or "retrying"
 * 2. Filter: nextRetryAt is in the past (time to retry)
 * 3. Filter: retryCount < 5 (haven't exceeded max retries)
 * 4. Limit: Process max 10 at a time (don't overwhelm system)
 * 5. For each webhook: Call retryWebhook()
 *
 * FOR EACH WEBHOOK:
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 1. Mark as "retrying"
 * 2. Increment retryCount
 * 3. Call PaymentService.handleWebhook() again
 * 4. If success:
 *    - Mark as "succeeded"
 *    - Log success with duration
 * 5. If failure:
 *    - Calculate next retry time (exponential backoff)
 *    - Mark as "pending" (or "failed" if max retries reached)
 *    - Log error with retry time
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * EXPONENTIAL BACKOFF FORMULA
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * CURRENT IMPLEMENTATION (2^n seconds):
 * backoff = 2^attemptNumber seconds
 *
 * Timeline:
 * Attempt 1: Now (webhook handler)
 * Attempt 2: Now + 2^1 = 2 seconds
 * Attempt 3: Now + 2^2 = 4 seconds
 * Attempt 4: Now + 2^3 = 8 seconds
 * Attempt 5: Now + 2^4 = 16 seconds
 * Total: 2 + 4 + 8 + 16 = 30 seconds to exhaust all retries
 * Max intervals: 16 seconds (for attempt 5)
 *
 * ALTERNATIVE (3^n * 5 minutes, for longer backoff):
 * backoff = 3^attemptNumber * 5 minutes
 *
 * Timeline (if you change formula):
 * Attempt 1: Now
 * Attempt 2: Now + 3^1 * 5 = +15 minutes
 * Attempt 3: Now + 3^2 * 5 = +45 minutes
 * Attempt 4: Now + 3^3 * 5 = +2.25 hours
 * Attempt 5: Now + 3^4 * 5 = +6.75 hours
 * Total: ~10 hours to exhaust retries
 *
 * WHY 2^n IS BETTER FOR OUR USE CASE:
 * - Most transient failures resolve within 30 seconds
 * - 2^n is aggressive enough to catch them
 * - 3^n is too patient (30 min to first retry might miss window)
 * - Stripe also has retry service (provides additional coverage)
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * THREAT MODEL & RESILIENCE
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Scenario 1: Database Temporarily Down (1 min)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * - Webhook attempt 1: Fails (DB connection timeout)
 * - Store in FailedWebhookModel
 * - Retry in 1 second: Still down
 * - Retry in 2 seconds: Still down
 * - Retry in 4 seconds: DB recovered! âœ… Success
 * - Result: Order fulfilled only 4 seconds late (user doesn't notice)
 *
 * Scenario 2: Redis Cache Down (permanent)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * - Webhook attempt 1: Fails (Redis connect timeout)
 * - Retries 2-5 with exponential backoff: Keep failing
 * - After 5 retries: Status marked as "failed"
 * - Alert sent to ops team
 * - Ops investigates and fixes Redis
 * - Manually trigger retry: Order fulfilled âœ…
 * - Result: System escalates to human, no data loss
 *
 * Scenario 3: Stripe Webhooks Lost (network failure)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * - Stripe sends webhook but network drops response
 * - Stripe doesn't see 200 OK, marks as failed
 * - Stripe retries webhook (their side, with retries)
 * - Eventually Stripe gives up and stops sending
 * - But: We also have idempotency check
 * - If webhook finally arrives: Already processed âœ…
 * - If webhook never arrives: Order stuck in "pending" status
 * - Recommendation: Admin dashboard shows pending orders
 *                   Ops can manually verify and update
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * MONITORING & OPERATIONS
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * HEALTHY SYSTEM:
 * - FailedWebhookModel mostly empty (immediate success)
 * - Occasionally has entries, but they succeed on retry 1-2
 * - No entries stuck with retryCount >= 4
 * - Logs show "Webhook retry succeeded" regularly
 *
 * UNHEALTHY SYSTEM WARNING SIGNS:
 * - FailedWebhookModel growing (more than 10 entries)
 * - Retries reaching max count (retryCount = 5)
 * - Same eventId retrying repeatedly
 * - Logs show repeated failures: database, redis, external service
 *
 * ALERTS TO SET UP:
 * - If FailedWebhookModel.count() > 100 â†’ Alert ops
 * - If webhook retryCount = 5 â†’ Alert ops (failed after all retries)
 * - If Stripe webhook latency > 10 seconds â†’ Investigate
 * - If payment fulfillment takes > 5 seconds â†’ Check database performance
 *
 * DEBUGGING FAILED WEBHOOKS:
 * - Query: db.failedwebhooks.find({ status: "failed" })
 * - Check: error message (what went wrong?)
 * - Check: lastAttemptAt (when was it last tried?)
 * - Check: retryCount (how many times retried?)
 * - Fix: Address root cause (database, redis, API)
 * - Retry: WebhookRetryService.retryById(webhookId)
 * - Verify: Check order status updated
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import { FailedWebhookModel } from "../models/failed-webhook.model";
import { PaymentService } from "./payment.service";
import { log } from "../utils/logger";

/**
 * WebhookRetryService - Background Retry Worker
 *
 * Runs continuously on server startup, checking for failed webhooks every 60 seconds
 * Implements exponential backoff to gracefully handle temporary failures
 *
 * USAGE:
 * â”€â”€â”€â”€â”€â”€
 * In server.ts (startup):
 *   WebhookRetryService.start(); // Starts with default 60 second interval
 *
 * On shutdown:
 *   WebhookRetryService.stop(); // Graceful cleanup
 *
 * Manual retry:
 *   WebhookRetryService.retryById(webhookId); // Immediate retry of specific webhook
 */
export class WebhookRetryService {
  private static isRunning = false;
  private static intervalId: NodeJS.Timeout | null = null;

  /**
   * Start the retry worker (call this in server.ts on startup)
   */
  static start(intervalMs: number = 60000) {
    // Every 1 minute
    if (this.isRunning) {
      log.warn("Webhook retry service already running");
      return;
    }

    this.isRunning = true;
    log.info("ğŸ”„ Starting webhook retry service", { intervalMs });

    this.intervalId = setInterval(() => {
      this.processRetries().catch((err) => {
        log.error("Webhook retry processing error", { error: err.message });
      });
    }, intervalMs);
  }

  /**
   * Stop the retry worker
   */
  static stop() {
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
      this.isRunning = false;
      log.info("â¹ï¸ Stopped webhook retry service");
    }
  }

  /**
   * Process all webhooks ready for retry
   */
  static async processRetries() {
    const now = new Date();

    // Find webhooks ready for retry
    const failedWebhooks = await FailedWebhookModel.find({
      status: { $in: ["pending", "retrying"] },
      nextRetryAt: { $lte: now },
      retryCount: { $lt: 5 }, // Max 5 retries
    }).limit(10); // Process 10 at a time

    if (failedWebhooks.length === 0) {
      return;
    }

    log.info(`ğŸ”„ Processing ${failedWebhooks.length} failed webhooks`);

    for (const webhook of failedWebhooks) {
      await this.retryWebhook(webhook);
    }
  }

  /**
   * Retry a single webhook
   */
  private static async retryWebhook(webhook: any) {
    const startTime = Date.now();

    try {
      log.info("ğŸ”„ Retrying webhook", {
        eventId: webhook.eventId,
        attempt: webhook.retryCount + 1,
      });

      webhook.status = "retrying";
      webhook.retryCount += 1;
      webhook.lastAttemptAt = new Date();
      await webhook.save();

      // Simulate webhook request
      const mockReq = {
        body: webhook.payload,
        headers: webhook.payload.headers || {},
      } as any;

      await PaymentService.handleWebhook(mockReq);

      // Success!
      webhook.status = "succeeded";
      await webhook.save();

      const duration = Date.now() - startTime;
      log.info("âœ… Webhook retry succeeded", {
        eventId: webhook.eventId,
        attempt: webhook.retryCount,
        duration,
      });
    } catch (error: any) {
      const duration = Date.now() - startTime;
      webhook.error = error.message;
      webhook.lastAttemptAt = new Date();

      // Calculate exponential backoff: 5min, 15min, 45min, 2h, 6h
      const backoffMinutes = Math.pow(3, webhook.retryCount) * 5;
      webhook.nextRetryAt = new Date(Date.now() + backoffMinutes * 60 * 1000);

      if (webhook.retryCount >= webhook.maxRetries) {
        webhook.status = "failed";
        log.error("âŒ Webhook retry failed - max retries reached", {
          eventId: webhook.eventId,
          maxRetries: webhook.maxRetries,
        });
      } else {
        webhook.status = "pending";
        log.warn("âš ï¸ Webhook retry failed - will retry", {
          eventId: webhook.eventId,
          attempt: webhook.retryCount,
          nextRetryAt: webhook.nextRetryAt,
          duration,
        });
      }

      await webhook.save();
    }
  }

  /**
   * Manually retry a specific webhook by ID
   */
  static async retryById(webhookId: string) {
    const webhook = await FailedWebhookModel.findById(webhookId);
    if (!webhook) {
      throw new Error("Webhook not found");
    }

    if (webhook.status === "succeeded") {
      throw new Error("Webhook already succeeded");
    }

    await this.retryWebhook(webhook);
  }
}
